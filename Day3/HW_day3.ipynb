{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee4f51c-e4db-4665-a559-c701fdbf47b5",
   "metadata": {},
   "source": [
    "## Intermediate Data Science\n",
    "\n",
    "#### University of Redlands - DATA 201\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data201.joannabieri.com](https://joannabieri.com/data201_intermediate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9fdce6-e271-45a8-b39d-2cbb635d4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic package imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.defaule = 'colab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56748c46-4a31-4738-b017-f60dfb91579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that you load the new packages from lecture if needed\n",
    "# !conda install -y lxml beautifulsoup4 html5lib\n",
    "# !conda install -y openpyxl xlrd\n",
    "# !conda install -y requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acae924-c516-45de-b938-8b77e3d5d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "doneieving notices: - \n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-64\n",
      "doneecting package metadata (repodata.json): / \n",
      "^Clving environment: \\ \n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.13/site-packages (5.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.13/site-packages (4.12.3)\n",
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.13/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from html5lib) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.13/site-packages (from html5lib) (0.5.1)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    }
   ],
   "source": [
    "!conda install -y lxml beautifulsoup4 html5lib\n",
    "!pip install lxml beautifulsoup4 html5lib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a98c1-f6c6-4915-9faf-7c878e0cd4fc",
   "metadata": {},
   "source": [
    "### You Try - 3 Warm-Up Problems From Lecture\n",
    "\n",
    "Here is a file that does not just read in nicely. See if you can use optional arguments to read it in.\n",
    "\n",
    "*Hint* How many (and which) rows of this data are just junk?\n",
    "\n",
    "**Terminal Command Line:**\n",
    "\n",
    "The command\n",
    "\n",
    "        cat data/ex4.csv\n",
    "\n",
    "if typed into a terminal prints out the contents of the file line by line. This lets us take a quick look at what is in the file. BEWARE - if you do this with a large file it will take a long time to print! Another great command is:\n",
    "\n",
    "        head data/ex4.csv\n",
    "\n",
    "would just show the first 10 lines of the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542020de-daf6-41fe-9b1e-d04966bbbaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# hey!\n",
      "a,b,c,d,message\n",
      "# just wanted to make things more difficult for you\n",
      "# who reads CSV files with computers, anyway?\n",
      "1,2,3,4,hello\n",
      "5,6,7,8,world\n",
      "9,10,11,12,foo\n"
     ]
    }
   ],
   "source": [
    "# This code lets you look at the data\n",
    "# the terminal command \"cat\" - prints the contents of a file\n",
    "# when we do !cat filename we can look at the \n",
    "file_name = 'data/ex4.csv'\n",
    "!cat data/ex4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3bebf5-f4c6-4a5d-a85b-1e6cc466e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# hey!\n",
      "a,b,c,d,message\n",
      "# just wanted to make things more difficult for you\n",
      "# who reads CSV files with computers, anyway?\n",
      "1,2,3,4,hello\n",
      "5,6,7,8,world\n",
      "9,10,11,12,foo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "!cat data/ex4.csv\n",
    "df = pd.read_csv(\"data/ex4.csv\", comment=\"#\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a471157-a23c-40db-bbfe-9a36aacd01d1",
   "metadata": {},
   "source": [
    "The comments in the code are the junk lines, and using comment = \"#\", pandas ignores lines for those and just reads abcd and message plus the three rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c524844-d646-4ecf-9b56-550fca9392b5",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3c1e2-ab82-47c1-8146-8ce6c53ae8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLES - DICTIONARY TO PANDAS\n",
    "my_dict = {\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": None,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5310943d-2085-40cb-a97a-5f481b8649f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Wes\n",
      "----------\n",
      "cities_lived\n",
      "['Akron', 'Nashville', 'New York', 'San Francisco']\n",
      "----------\n",
      "pet\n",
      "None\n",
      "----------\n",
      "siblings\n",
      "[{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']}, {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for key in my_dict.keys():\n",
    "    print(key)\n",
    "    print(my_dict[key])\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da36aaab-6724-46ec-9fe2-6ee3abe1bec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This code will give you an error\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(my_dict)\n\u001b[1;32m      3\u001b[0m df\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# This code will give you an error\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c98e4a3-5243-4fbe-891c-8083803a4d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>hobbies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scott</td>\n",
       "      <td>34</td>\n",
       "      <td>[guitars, soccer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katie</td>\n",
       "      <td>42</td>\n",
       "      <td>[diving, art]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age            hobbies\n",
       "0  Scott   34  [guitars, soccer]\n",
       "1  Katie   42      [diving, art]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code will work\n",
    "df = pd.DataFrame(my_dict['siblings'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108314b9-08cd-4ad4-a400-f16612f1bf5d",
   "metadata": {},
   "source": [
    "### You Try:\n",
    "\n",
    "Can you explain what is going on in the examples above? Why does one give an error and the other works? What specifically is it about focusing in on the siblings data that allows pandas to read this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c04cb-62c3-4fa7-8335-33008bdab4fd",
   "metadata": {},
   "source": [
    "**Your explanation here:** In the examples above, one gives a error because pd.DataFrame(my_dict) does not fix the fact that the dictionary mixes values of different lengths, and pandas requires all columns to have the same number of rows. So thats why I am getting the ValueError error. pd.DataFrame(my_dict['siblings']) works because here each dict has the same keys, so now Pandas can use each dict as one row, and gives us equal length columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57e65d-d87d-48eb-af95-e21558ba8412",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901faf7f-d773-4942-8c4c-9b7861bae16e",
   "metadata": {},
   "source": [
    "### You Try\n",
    "\n",
    "Here is an example website that contains a table:\n",
    "\n",
    "https://www.scrapethissite.com/pages/forms/\n",
    "\n",
    "1. Open the website in your browser. Does the page that appears contain ALL the data about hockey teams?\n",
    "2. How does the web address change when you select the second page of the website.\n",
    "3. See if you can write code that will scrape all of the data. HINT: I would use a for loop that updates the web address and appends the new table to a list.\n",
    "4. Once you have the list of tables can you get them into a single data frame and save the data as a .csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa12cab-9c94-4a07-8687-201a44eaf271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is how I could get one page\n",
    "website = 'https://www.scrapethissite.com/pages/forms/'\n",
    "tables = pd.read_html(website)\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a5a8fd-8b99-46a6-902c-aded7c2144e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>OT Losses</th>\n",
       "      <th>Win %</th>\n",
       "      <th>Goals For (GF)</th>\n",
       "      <th>Goals Against (GA)</th>\n",
       "      <th>+ / -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>1990</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550</td>\n",
       "      <td>299</td>\n",
       "      <td>264</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>1990</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388</td>\n",
       "      <td>292</td>\n",
       "      <td>278</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575</td>\n",
       "      <td>344</td>\n",
       "      <td>263</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>1990</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613</td>\n",
       "      <td>284</td>\n",
       "      <td>211</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detroit Red Wings</td>\n",
       "      <td>1990</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425</td>\n",
       "      <td>273</td>\n",
       "      <td>298</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Name  Year  Wins  Losses  OT Losses  Win %  Goals For (GF)  \\\n",
       "0       Boston Bruins  1990    44      24        NaN  0.550             299   \n",
       "1      Buffalo Sabres  1990    31      30        NaN  0.388             292   \n",
       "2      Calgary Flames  1990    46      26        NaN  0.575             344   \n",
       "3  Chicago Blackhawks  1990    49      23        NaN  0.613             284   \n",
       "4   Detroit Red Wings  1990    34      38        NaN  0.425             273   \n",
       "\n",
       "   Goals Against (GA)  + / -  \n",
       "0                 264     35  \n",
       "1                 278     14  \n",
       "2                 263     81  \n",
       "3                 211     73  \n",
       "4                 298    -25  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "website = 'https://www.scrapethissite.com/pages/forms/'\n",
    "all_tables = []\n",
    "for page in range(1, 6):\n",
    "    url = website + '?page_num=' + str(page)\n",
    "\n",
    "    tables = pd.read_html(url)\n",
    "    all_tables.append(tables[0])\n",
    "\n",
    "df = pd.concat(all_tables)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a62c16-23e6-4d49-be69-0f238095728f",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4c4e3-f4e8-490c-9490-f8ed3e55d039",
   "metadata": {},
   "source": [
    "## Reading and Writing Data - Day3 HW\n",
    "\n",
    "## Homework 3\n",
    "\n",
    "Go to Kaggle Datasets: https://www.kaggle.com/datasets\n",
    "\n",
    "Find a data set that you are interested in looking at. You are welcome to work together and choose a data set as a group! You should read in this data and do some basic statistics on the data set. Answer the following questions:\n",
    "\n",
    "1. Tell your reader about the data: Where did you get it? When did you access it? Who owns it? What is the license? Are there any acknowledgments that you should give for using the data? All of this should be on the Kaggle page\n",
    "2. How many variables and observations?\n",
    "3. What type of data is contained? Was it read in as strings, ints, floats?\n",
    "4. Are there any NaNs or weird data types that you can see?\n",
    "5. Most Kaggle datasets contain some basic stats or visualizations on the download page. See if you can recreate some of the plots or data you see on the website.\n",
    "6. Come up with at least one question of your own that you can answer by analyzing the data.\n",
    "7. Create a dataframe with just the data you need to answer your question - save the data subset to a file (your choice of type)\n",
    "8. **In a NEW NOTEBOOK** Write code that reads in your subset of the data, markdown that explains clearly where you got the data originally (license and references included) and the process you took to create your subset, a description of the question you are answering, and code that can reliably run and answer your question followed by words that explain your results.\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "Your final notebooks should:\n",
    "\n",
    "- [ ] Be completely new notebooks with just the Day3 stuff in it: First the code that creates your data and second the code that reads in the data and does the analysis. \n",
    "- [ ] Be reproducible with junk code removed.\n",
    "- [ ] Have lots of language describing what you are doing, especially for questions you are asking or things that you find interesting about the data. Use complete sentences, nice headings, and good markdown formatting: https://www.markdownguide.org/cheat-sheet/\n",
    "- [ ] It should run without errors from start to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ac618-b37f-4dba-9c30-0bd4822b736e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
