{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d35f17b-9198-46d0-817e-73ef34eea956",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "    html: \n",
    "        theme: minty\n",
    "        fontsize: 1.1em\n",
    "        page-layout: article\n",
    "        mermaid:\n",
    "            theme: default\n",
    "\n",
    "toc: true\n",
    "toc-depth: 5\n",
    "toc-expand: 2\n",
    "editor: visual\n",
    "warning: false\n",
    "error: false\n",
    "code-overflow: wrap\n",
    "eval: true\n",
    "\n",
    "title: \"Intermediate Data Science\"\n",
    "subtitle: \"Data Loading, Storage, and File Formats\"\n",
    "author: \"Joanna Bieri <br> DATA201\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393c8ad4-4b58-43a8-91b7-f5c0ae5b7386",
   "metadata": {},
   "source": [
    "# Intermediate Data Science\n",
    "\n",
    "## Important Information\n",
    "\n",
    "- Email: [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "- Office Hours take place in Duke 209 -- [Office Hours Schedule](https://joannabieri.com/schedule.html)\n",
    "- [Class Website](https://joannabieri.com/data201.html)\n",
    "- [Syllabus](https://joannabieri.com/data201/IntermediateDataScience.pdf)\n",
    "\n",
    "## Data and File Formats\n",
    "\n",
    "Reading in data and making it accessible to your data science techniques is the first step in data science success. This is called data loading or sometimes parsing. As a data scientists you may not have complete control over the format of your data when you first start a project. So it is part of your job to find a way to load it and parse it.\n",
    "\n",
    "Here are some important data types:\n",
    "\n",
    "- **CSV (Comma-Separated Values)**\n",
    "\n",
    "CSV is a simple, text-based format that stores tabular data. Each line in the file represents a data record (a row), and each record consists of one or more fields (columns) separated by commas. The data does not have types and is read in as strings.\n",
    "\n",
    "- **Text - General**\n",
    "\n",
    "This is a generalization of CSV types where the data could be just written to lines, or stored as a single string. Once this is read in you would need to do a lot of work to parse it and turn it in to data. It is extremely inefficient, but sometimes this is how the data comes to you.\n",
    "\n",
    "- **JSON (JavaScript Object Notation)**\n",
    "  \n",
    "JSON is a text-based format for representing semi-structured data using key-value pairs, similar to Python dictionaries. It's great for data that has a nested or hierarchical structure. It is human readable but less efficient for storing large flat tables.\n",
    "\n",
    "- **Apache Parquet**\n",
    "\n",
    "Parquet is a binary, columnar storage format. Instead of storing data row-by-row like a CSV, it stores all the values for a single column together. This structure is highly optimized for analytical queries. This format can make it really fast to read in subsets of the data and allows for compression of the data. It is not human readable.\n",
    "\n",
    "- **Pickle**\n",
    "\n",
    "Pickle is a Python-specific binary format used for serializing and de-serializing Python objects. It can turn almost any Python object (like a list, a dictionary, or even a trained machine learning model) into a stream of bytes that can be saved to a file. It can handle very complex python objects and is extremely easy to use. Can have some compatibility and security issues.\n",
    "\n",
    "- **HDF5 (Hierarchical Data Format 5)**\n",
    "\n",
    "HDF5 is a high-performance binary format designed to store and organize massive amounts of data. It acts like a file system within a single file, allowing you to store multiple datasets (e.g., arrays, tables) in a hierarchical structure. It is great for large,complex scientific datasets, but has a steep learning curve.\n",
    "\n",
    "- **Geospatial Data**\n",
    "\n",
    "Geospatial data are typically categorized as either vector (representing features with points, lines, and polygons) or raster (representing features as a grid of pixels or cells). There are many formats for these files. One popular one is GeoJSON - which leverages the JSON file format but allows for vector based data. GeoTIFF is standard for raster data.\n",
    "\n",
    "- **Web APIs (Application Programming Interface) - not a data type but a data access type**\n",
    "\n",
    "Many websites have public APIs providing data feeds via one of the formats above. If a website has an API , you should use this interface to get data rather than trying to scrape the site.\n",
    "\n",
    "- **Databases - again not a data type**\n",
    "\n",
    "In many cases data can be stored in a database: SQL server, MySQL, NoSQL Mongo, or Graph Databases. In these cases you *query* the database to get access to subsets of the data. The choice of database is highly dependent on the project needs and scalability. \n",
    "\n",
    "\n",
    "## Pandas Data Loading Functions\n",
    "\n",
    "Most of this class will focus on using Pandas for our data management. NOTE: if you are a geospatial student there is a sister package called GeoPandas that has very similar functionality to Pandas.\n",
    "\n",
    "| Function                | Type     | Description                                                                 | Common File Types |\n",
    "|--------------------------|----------|-----------------------------------------------------------------------------|------------------|\n",
    "| `pd.read_csv()`          | Text     | Reads comma-separated values into a DataFrame.                              | `.csv` |\n",
    "| `pd.read_table()`        | Text     | Reads general delimited text files (default delimiter is tab).               | `.txt`, `.tsv` |\n",
    "| `pd.read_fwf()`          | Text     | Reads fixed-width formatted text files.                                      | `.txt` |\n",
    "| `pd.read_json()`         | Text     | Reads JSON (JavaScript Object Notation) data.                               | `.json` |\n",
    "| `pd.read_html()`         | Text     | Parses HTML tables and returns them as a list of DataFrames.                | `.html` |\n",
    "| `pd.read_xml()`          | Text     | Reads XML data into a DataFrame.                                            | `.xml` |\n",
    "| `pd.read_sql()`          | Text     | Reads data from a SQL query or database connection.                         | (SQL database) |\n",
    "| `pd.read_excel()`        | Binary   | Reads Excel spreadsheets (both `.xls` and `.xlsx`).                         | `.xls`, `.xlsx` |\n",
    "| `pd.read_pickle()`       | Binary   | Reads a Python object saved with `pickle`.                                  | `.pkl` |\n",
    "| `pd.read_parquet()`      | Binary   | Reads Apache Parquet columnar storage files.                                | `.parquet` |\n",
    "| `pd.read_orc()`          | Binary   | Reads Apache ORC columnar storage files.                                    | `.orc` |\n",
    "| `pd.read_feather()`      | Binary   | Reads Feather binary columnar storage files.                                | `.feather` |\n",
    "| `pd.read_sas()`          | Binary   | Reads SAS files (both XPORT and SAS7BDAT formats).                          | `.xpt`, `.sas7bdat` |\n",
    "| `pd.read_spss()`         | Binary   | Reads SPSS system files.                                                    | `.sav`, `.zsav` |\n",
    "| `pd.read_stata()`        | Binary   | Reads Stata dataset files.                                                  | `.dta` |\n",
    "| `pd.read_hdf()`          | Binary   | Reads HDF5 (Hierarchical Data Format) files.                                | `.h5`, `.hdf5` |\n",
    "\n",
    "## Python Data Loading Functions\n",
    "\n",
    "- **Read Write**\n",
    "\n",
    "A standard build in way to read in files. It will read/write text line by line. Does not save variable types and everything is assumed to be a string.\n",
    "\n",
    "```{python}\n",
    "# ---- WRITE ----\n",
    "data = [\n",
    "    \"Name,Score\",\n",
    "    \"Alice,85\",\n",
    "    \"Bob,92\",\n",
    "    \"Charlie,78\"\n",
    "]\n",
    "\n",
    "with open(\"students.txt\", \"w\") as f:\n",
    "    for line in data:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "# ---- READ ----\n",
    "with open(\"students.txt\", \"r\") as f:\n",
    "    contents = f.readlines()\n",
    "\n",
    "print(\"Contents of students.txt:\")\n",
    "for line in contents:\n",
    "    print(line.strip())\n",
    "\n",
    "```\n",
    "\n",
    "- **JSON**\n",
    "\n",
    "Great for reading in or saving dictionaries. It will preserve some data types: dict (keys must be strings), lists/tuple (tuples become lists), string, int, float, boolean, and None. Other data types will not be properly encoded without extra work.\n",
    "\n",
    "```{python}\n",
    "import json\n",
    "\n",
    "# Some Python object (dict with student scores)\n",
    "students = {\"Alice\": 85, \"Bob\": 92, \"Charlie\": 78}\n",
    "\n",
    "# ---- WRITE ----\n",
    "with open(\"students.json\", \"w\") as f:\n",
    "    json.dump(students, f, indent=4)   # indent=4 makes it pretty\n",
    "\n",
    "# ---- READ ----\n",
    "with open(\"students.json\", \"r\") as f:\n",
    "    loaded_students = json.load(f)\n",
    "\n",
    "print(\"Data loaded from JSON:\")\n",
    "print(loaded_students)\n",
    "```\n",
    "\n",
    "- **Pickle**\n",
    "\n",
    "Great in Python and preserves Python types. However, pickle is Python specific and it is not easy to load .pkl files into other languages. \n",
    "\n",
    "```{python}\n",
    "import pickle\n",
    "\n",
    "# Some Python object with mixed types\n",
    "students = {\n",
    "    \"Alice\": (85, \"A\"),    # tuple\n",
    "    \"Bob\": {\"math\": 92},   # dict\n",
    "    \"Charlie\": [78, 80]    # list\n",
    "}\n",
    "\n",
    "# ---- WRITE ----\n",
    "with open(\"students.pkl\", \"wb\") as f:   # 'wb' = write binary\n",
    "    pickle.dump(students, f)\n",
    "\n",
    "# ---- READ ----\n",
    "with open(\"students.pkl\", \"rb\") as f:   # 'rb' = read binary\n",
    "    loaded_students = pickle.load(f)\n",
    "\n",
    "print(\"Original:\", students)\n",
    "print(\"Loaded:\", loaded_students)\n",
    "print(\"Types preserved:\", type(loaded_students[\"Alice\"]))\n",
    "```\n",
    "\n",
    "## Code Examples\n",
    "\n",
    "Here are some examples of reading in these data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cf096b4a-cb9c-4f53-83e9-2a27e9604776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic package imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.defaule = 'colab'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1af5b0-90f2-4cc4-8697-a2b69bf34962",
   "metadata": {},
   "source": [
    "## Optional Arguments in Pandas Data Loading\n",
    "\n",
    "All of the Pandas functions for Data Loading have optional arguments. These help refine how you load the data, how much data you load, data conversion, and even what to do with bad data. Here are the main categories:\n",
    "\n",
    "- *Indexing* These arguments help you choose which columns or rows are returned in the DataFrame, and whether or not to get column or index names from the data set.\n",
    "- *Type inference and data conversion*  These arguments help you to converts data types or customize data as you read it in. This might include missing value markers.\n",
    "- *Date and time parsing* These arguments help you combine date and time information spread over multiple columns into a single column in the result.\n",
    "- *Iterating* Useful for very large files - you can load in chunks.\n",
    "- *Unclean data issues* These arguments allow you to skip over header or footer rows, or tell Pandas what to do with comments or numbers that are split by commas.\n",
    "\n",
    "It can be overwhelming when you see the full list of optional arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d747283e-7479-4764-823b-9709ce14baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see the documentation for read_csv()\n",
    "# pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a311928-24c6-4d79-b644-82ef36a6f58b",
   "metadata": {},
   "source": [
    "## Reading in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f44350-38e1-4423-90fa-c12e62b597f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/ex1.csv'\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf65c42-c1b5-4249-b1e7-449e29978ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e681e64-25ef-41cd-b46e-9eac69a8e184",
   "metadata": {},
   "source": [
    "Notice that this data is read in with a nice header row telling Pandas how to label the columns. This is not always the case! Pandas assumes that the first row is a header and will lead to some confusing results if you just read in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc69d98-07f6-4098-86f4-4714a4d2b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/ex2.csv'\n",
    "df_nh = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6bea13-39ae-43cd-97e4-eb7157552c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>hello</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   2   3   4  hello\n",
       "0  5   6   7   8  world\n",
       "1  9  10  11  12    foo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b32ca-71b7-4dac-bb04-cdf97c96648c",
   "metadata": {},
   "source": [
    "Notice how the first row of the data was made into the column labels! This is not what we want... so we have to look into the optional arguments to correct the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762b0f8e-5037-4481-ae33-619d7144e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3      4\n",
       "0  1   2   3   4  hello\n",
       "1  5   6   7   8  world\n",
       "2  9  10  11  12    foo"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With default numbered column names\n",
    "file_name = 'data/ex2.csv'\n",
    "df_nh = pd.read_csv(file_name, header=None)\n",
    "df_nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9b7f89-cd99-427b-9bfe-33e062f2f612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With column names that you give\n",
    "file_name = 'data/ex2.csv'\n",
    "df_nh = pd.read_csv(file_name, header=None, names=[\"a\", \"b\", \"c\", \"d\", \"message\"])\n",
    "df_nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc9405c-cf9c-45d1-b2c9-d48e6f741f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a   b   c   d\n",
       "message               \n",
       "hello    1   2   3   4\n",
       "world    5   6   7   8\n",
       "foo      9  10  11  12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even move the \"message\" column to be the index (row labels)\n",
    "names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n",
    "pd.read_csv(\"data/ex2.csv\", names=names, index_col=\"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e0745-1e87-441c-93e2-1c57a5f6c0d5",
   "metadata": {},
   "source": [
    "## You Try\n",
    "\n",
    "Here is a file that does not just read in nicely. See if you can use optional arguments to read it in.\n",
    "\n",
    "*Hint* How many (and which) rows of this data are just junk?\n",
    "\n",
    "**Terminal Command Line:**\n",
    "\n",
    "The command\n",
    "\n",
    "        cat data/ex4.csv\n",
    "\n",
    "if typed into a terminal prints out the contents of the file line by line. This lets us take a quick look at what is in the file. BEWARE - if you do this with a large file it will take a long time to print! Another great command is:\n",
    "\n",
    "        head data/ex4.csv\n",
    "\n",
    "would just show the first 10 lines of the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3b9200f-d09f-42f0-9658-cce6a92c2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# hey!\n",
      "a,b,c,d,message\n",
      "# just wanted to make things more difficult for you\n",
      "# who reads CSV files with computers, anyway?\n",
      "1,2,3,4,hello\n",
      "5,6,7,8,world\n",
      "9,10,11,12,foo\n"
     ]
    }
   ],
   "source": [
    "# This code lets you look at the data\n",
    "# the terminal command \"cat\" - prints the contents of a file\n",
    "# when we do !cat filename we can look at the \n",
    "file_name = 'data/ex4.csv'\n",
    "!cat data/ex4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2eac7ae-725c-4a63-bcc3-adcb7b238a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61c24f-756b-4ff9-9780-b80f961b4b81",
   "metadata": {},
   "source": [
    "## Missing Data in CSV files\n",
    "\n",
    "Here is another file that could give you issues. Notice that when we look at the file there are THREE different types of missing values:\n",
    "\n",
    "1. One marked NA\n",
    "2. One just missing ,,\n",
    "3. One marked None\n",
    "\n",
    "all of these could mean different things in our data set, but look what happens when Pandas reads them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce1e237-6797-4a53-8f30-9ca3ed18263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something,a,b,c,d,message\n",
      "one,1,2,3,4,NA\n",
      "two,5,6,,8,world\n",
      "three,9,10,11,None,foo\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/ex4.csv'\n",
    "!cat data/ex5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a059da0f-abbf-49ec-a278-494a0ca0f12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b     c    d message\n",
       "0       one  1   2   3.0  4.0     NaN\n",
       "1       two  5   6   NaN  8.0   world\n",
       "2     three  9  10  11.0  NaN     foo"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'data/ex5.csv'\n",
    "df_nan = pd.read_csv(file_name)\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3baae8-4eae-4b37-b760-f0f484084045",
   "metadata": {},
   "source": [
    "All three of these are treated as NaN! So we should be EXTRA careful when we see NaNs in our Pandas data! There are ways to specify to pandas how to handle special types of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72ce07eb-6d40-4d2f-9ee5-3625ab6e1f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b   c     d message\n",
       "0       one  1   2   3     4     NaN\n",
       "1       two  5   6         8   world\n",
       "2     three  9  10  11  None     foo"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan = pd.read_csv(\"data/ex5.csv\", keep_default_na=False,\n",
    "                      na_values=[\"NA\"])\n",
    "\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88924d7c-a89e-4cb8-bb9b-048883512dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   something      a      b      c      d  message\n",
       "0      False  False  False  False  False     True\n",
       "1      False  False  False  False  False    False\n",
       "2      False  False  False  False  False    False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b3bd9-93fe-4347-b761-218fcbec7e66",
   "metadata": {},
   "source": [
    "## Weird things do happen in CSV files!\n",
    "\n",
    "Notice what happens when we try to read in a .txt file that is not comman separated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0036a0a8-0393-41ff-83ee-664f508fd51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            A         B         C\n",
      "aaa -0.264438 -1.026059 -0.619500\n",
      "bbb  0.927272  0.302904 -0.032399\n",
      "ccc -0.264273 -0.386314 -0.217601\n",
      "ddd -0.871858 -0.348382  1.100491\n"
     ]
    }
   ],
   "source": [
    "!cat data/ex3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bde70da5-6474-48c8-98d6-2e7cbc1fb6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A         B         C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa -0.264438 -1.026059 -0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbb  0.927272  0.302904 -0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ccc -0.264273 -0.386314 -0.217601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ddd -0.871858 -0.348382  1.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A         B         C\n",
       "0  aaa -0.264438 -1.026059 -0.619500\n",
       "1  bbb  0.927272  0.302904 -0.032399\n",
       "2  ccc -0.264273 -0.386314 -0.217601\n",
       "3  ddd -0.871858 -0.348382  1.100491"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oops = pd.read_csv(\"data/ex3.txt\")\n",
    "df_oops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e874bdf-42ad-4d63-af43-e3a562358079",
   "metadata": {},
   "source": [
    "What happened here? Well our file was not comma separated so pandas just did its best and separated on the line breaks. But not all is lost, we just need to tell Pandas that the data is separated by spaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19580f89-5a58-453f-9a75-7ce86f4ba687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>-0.264438</td>\n",
       "      <td>-1.026059</td>\n",
       "      <td>-0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbb</th>\n",
       "      <td>0.927272</td>\n",
       "      <td>0.302904</td>\n",
       "      <td>-0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccc</th>\n",
       "      <td>-0.264273</td>\n",
       "      <td>-0.386314</td>\n",
       "      <td>-0.217601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd</th>\n",
       "      <td>-0.871858</td>\n",
       "      <td>-0.348382</td>\n",
       "      <td>1.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C\n",
       "aaa -0.264438 -1.026059 -0.619500\n",
       "bbb  0.927272  0.302904 -0.032399\n",
       "ccc -0.264273 -0.386314 -0.217601\n",
       "ddd -0.871858 -0.348382  1.100491"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oops = pd.read_csv(\"data/ex3.txt\", sep=\"\\\\s+\")\n",
    "df_oops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5071ee6-f2c7-41cc-9645-3739013a7b55",
   "metadata": {},
   "source": [
    "## Reading in Pieces of CSV files\n",
    "\n",
    "Sometimes your data is REALLY big and you just want to read in small pieces of it. This is especially useful when you are doing initial exploration of a HUGE data set. It allows you to look at a small bit of data quickly before diving into the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ce4582a-dc72-40bc-a338-aa8627666eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ex6.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40f70eac-8747-44a0-83b5-e99a4695f8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467976</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>-0.295344</td>\n",
       "      <td>-1.824726</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.358893</td>\n",
       "      <td>1.404453</td>\n",
       "      <td>0.704965</td>\n",
       "      <td>-0.200638</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.501840</td>\n",
       "      <td>0.659254</td>\n",
       "      <td>-0.421691</td>\n",
       "      <td>-0.057688</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204886</td>\n",
       "      <td>1.074134</td>\n",
       "      <td>1.388361</td>\n",
       "      <td>-0.982404</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.354628</td>\n",
       "      <td>-0.133116</td>\n",
       "      <td>0.283763</td>\n",
       "      <td>-0.837063</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        one       two     three      four key\n",
       "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
       "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
       "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
       "3  0.204886  1.074134  1.388361 -0.982404   R\n",
       "4  0.354628 -0.133116  0.283763 -0.837063   Q"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/ex6.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c9e2019-add4-43a6-8109-a0aab56b27bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x7c371345f9d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = pd.read_csv(\"data/ex6.csv\", chunksize=5)\n",
    "chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20dbd149-ef1e-4aea-bf26-3a30b7dace7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets say we just want to grab the keys and do a value_counts\n",
    "# without holding the whole dataset in memory\n",
    "\n",
    "# Create an empty series\n",
    "tot = pd.Series([], dtype='int64')\n",
    "# Loop over each piece in the chunker\n",
    "for piece in chunker:\n",
    "    # Add the value counts for that chunk to the previous size.\n",
    "    # allowing for adding zero in the case that we don't observe a key in that chunk\n",
    "    tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf6ca0a8-a237-43f7-bc69-745ebe8c9d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key\n",
       "E    368.0\n",
       "X    364.0\n",
       "L    346.0\n",
       "O    343.0\n",
       "Q    340.0\n",
       "M    338.0\n",
       "J    337.0\n",
       "F    335.0\n",
       "K    334.0\n",
       "H    330.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the values decending\n",
    "tot = tot.sort_values(ascending=False)\n",
    "# Show the top 10 values in the output\n",
    "tot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4e462a2-62d2-4dfc-9968-acfa2ec14439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that chunker has been used it is empty\n",
    "# This code will print nothing!\n",
    "for piece in chunker:\n",
    "    print(piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7f090-97bc-4439-ab5d-e93ea8b2f1c7",
   "metadata": {},
   "source": [
    "## This is just the beginning!\n",
    "\n",
    "There is no way that we can go over every possible data catastrophe that can happen when reading in a .csv. But just know that there are lots of arguments that can help you to read in the data properly. It is always worth glancing at the data using cat or head in a terminal just to see what you should expect.\n",
    "\n",
    "## Writing data to a CSV file\n",
    "\n",
    "Above we created a Pandas Series object that holds all the value counts for a large file. Now what if we want to save it so we don't have to run that process again? We can use the .to_csv() command to save the data as a comma separated file. Again there are LOTS of optional arguments:\n",
    "\n",
    "- sep='|' -- would change the separator from a comma to a |\n",
    "- index=False -- would not save the index as a separate column. If you look at the file generated by the code below, the index (row labels) are saved as a column in the final dataset.\n",
    "- header=False -- would tell pandas not to save the column names\n",
    "- columns = [enter col names here] -- would only save specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc633793-9829-499f-aff5-ed5fb498426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this command will create a new file in your working directory\n",
    "tot.to_csv('key_value_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a517d51c-09dd-4640-9065-68aaec3570d7",
   "metadata": {},
   "source": [
    "## Reading and Writing in JSON files\n",
    "\n",
    "JSON files are stored in a format that mimics python dictionaries. Here you can see what is inside a .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1976fa5e-9ed1-4433-977c-40b7645c5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"a\": 1, \"b\": 2, \"c\": 3},\n",
      " {\"a\": 4, \"b\": 5, \"c\": 6},\n",
      " {\"a\": 7, \"b\": 8, \"c\": 9}]\n"
     ]
    }
   ],
   "source": [
    "!cat data/example.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7b48986-f0ab-4f74-b9aa-3b26e36f722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read it into pandas\n",
    "df = pd.read_json(\"data/example.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8538cddf-ba83-4ad8-a12a-b0d20da0b9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  sum\n",
       "0  1  2  3    6\n",
       "1  4  5  6   15\n",
       "2  7  8  9   24"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a small change\n",
    "df[\"sum\"] = df.sum(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52521a57-b08d-4941-837f-f378a4ba4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "# This will save to your working directory\n",
    "df.to_json('example_with_sum.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ce2b2-3e2e-4fa6-86d6-8ce0b8bf191f",
   "metadata": {},
   "source": [
    "## Pandas and JSON files\n",
    "\n",
    "- You can use either Pandas or import json to interact with json\n",
    "- Pandas is very good at reading in a dictionary - BUT the data must have the right shapes - all values must have the same number of rows\n",
    "\n",
    "Here is an example dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "768e905f-39d5-440b-9cd8-75a5e0cf7fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Wes',\n",
       " 'cities_lived': ['Akron', 'Nashville', 'New York', 'San Francisco'],\n",
       " 'pet': None,\n",
       " 'siblings': [{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']},\n",
       "  {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": None,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378c443-b683-4f98-ab13-6788e78809a3",
   "metadata": {},
   "source": [
    "Notice that in this data each key had a different length object stored in it. Also each of the objects is different!\n",
    "\n",
    "This is 100% okay to do in a dictionary, but Pandas expects things to be cleaner. Let's take a look at the parts of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff0b9c31-3758-4ee8-9535-4343b3022eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Wes\n",
      "----------\n",
      "cities_lived\n",
      "['Akron', 'Nashville', 'New York', 'San Francisco']\n",
      "----------\n",
      "pet\n",
      "None\n",
      "----------\n",
      "siblings\n",
      "[{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']}, {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for key in my_dict.keys():\n",
    "    print(key)\n",
    "    print(my_dict[key])\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44a11759-ae33-4b08-b109-010e412b94e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/DATA201-F25/lib/python3.13/site-packages/pandas/core/frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/DATA201-F25/lib/python3.13/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/DATA201-F25/lib/python3.13/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/DATA201-F25/lib/python3.13/site-packages/pandas/core/internals/construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# This code will give you an error\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9964f7ec-1697-467c-b12b-0bb043c24101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>hobbies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scott</td>\n",
       "      <td>34</td>\n",
       "      <td>[guitars, soccer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katie</td>\n",
       "      <td>42</td>\n",
       "      <td>[diving, art]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age            hobbies\n",
       "0  Scott   34  [guitars, soccer]\n",
       "1  Katie   42      [diving, art]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code will work\n",
    "df = pd.DataFrame(my_dict['siblings'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1917a942-fc16-415a-9a9d-eb925b052c84",
   "metadata": {},
   "source": [
    "## You Try\n",
    "\n",
    "Can you explain what is going on in the examples above? Why does one give an error and the other works? What specifically is it about focusing in on the siblings data that allows pandas to read this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5daf3bc-5eec-49c2-88bf-0a72b2534266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d8b3fe5-cbc9-4ff5-91e0-2968020fb2d5",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "Python has many libraries for web scraping: lxml, Beautiful Soup, and html5lib. These packages are great for more advanced web scraping and dealing with malformed files. However, Pandas has a good build in function that will read html and parse tables as DataFrame objects. \n",
    "\n",
    "First, lets make sure you have the web scraping packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed416bb-22b7-4a6a-b467-ef97b6d86a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y lxml beautifulsoup4 html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a86478-2f4e-4048-b065-b10efeeb93d5",
   "metadata": {},
   "source": [
    "We are just going to look at .read_html() for right now. The book has a nice discussion of how to parse .xml files if you are interested in getting deeper into web scraping. There are lots of other tutorials online and we will talk more about web scraping later in the semester.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4893c3-f2c5-4207-bc71-9889e269c302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This file comes from the book github. If you want to see the full data look here:\n",
    "# https://www.fdic.gov/bank-failures/failed-bank-list\n",
    "\n",
    "tables = pd.read_html(\"data/fdic_failed_bank_list.html\")\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940df76a-7f45-4b54-80f5-d666228a90c6",
   "metadata": {},
   "source": [
    "Pandas reads in the .html files and looks for tables. It puts the results in a list of data frames. In the example above Pandas found one table so to look at the DataFrame for this table we need to get it out of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6f6211-7d58-4af7-b339-35e5f19f8d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>City</th>\n",
       "      <th>ST</th>\n",
       "      <th>CERT</th>\n",
       "      <th>Acquiring Institution</th>\n",
       "      <th>Closing Date</th>\n",
       "      <th>Updated Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allied Bank</td>\n",
       "      <td>Mulberry</td>\n",
       "      <td>AR</td>\n",
       "      <td>91</td>\n",
       "      <td>Today's Bank</td>\n",
       "      <td>September 23, 2016</td>\n",
       "      <td>November 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Woodbury Banking Company</td>\n",
       "      <td>Woodbury</td>\n",
       "      <td>GA</td>\n",
       "      <td>11297</td>\n",
       "      <td>United Bank</td>\n",
       "      <td>August 19, 2016</td>\n",
       "      <td>November 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First CornerStone Bank</td>\n",
       "      <td>King of Prussia</td>\n",
       "      <td>PA</td>\n",
       "      <td>35312</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>May 6, 2016</td>\n",
       "      <td>September 6, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trust Company Bank</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>9956</td>\n",
       "      <td>The Bank of Fayette County</td>\n",
       "      <td>April 29, 2016</td>\n",
       "      <td>September 6, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North Milwaukee State Bank</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>20364</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>March 11, 2016</td>\n",
       "      <td>June 16, 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Bank Name             City  ST   CERT  \\\n",
       "0                   Allied Bank         Mulberry  AR     91   \n",
       "1  The Woodbury Banking Company         Woodbury  GA  11297   \n",
       "2        First CornerStone Bank  King of Prussia  PA  35312   \n",
       "3            Trust Company Bank          Memphis  TN   9956   \n",
       "4    North Milwaukee State Bank        Milwaukee  WI  20364   \n",
       "\n",
       "                 Acquiring Institution        Closing Date       Updated Date  \n",
       "0                         Today's Bank  September 23, 2016  November 17, 2016  \n",
       "1                          United Bank     August 19, 2016  November 17, 2016  \n",
       "2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  \n",
       "3           The Bank of Fayette County      April 29, 2016  September 6, 2016  \n",
       "4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failures = tables[0]\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47607ccf-7f9b-4b3f-8be8-5ead4c60bab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880942ed-4c35-4e5a-b374-e2b91cccd520",
   "metadata": {},
   "source": [
    "## You Try\n",
    "\n",
    "Here is an example website that contains a table:\n",
    "\n",
    "https://www.scrapethissite.com/pages/forms/\n",
    "\n",
    "1. Open the website in your browser. Does the page that appears contain ALL the data about hockey teams?\n",
    "2. How does the web address change when you select the second page of the website.\n",
    "3. See if you can write code that will scrape all of the data. HINT: I would use a for loop that updates the web address and appends the new table to a list.\n",
    "4. Once you have the list of tables can you get them into a single data frame and save the data as a .csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828563a2-a215-4c2f-8952-3e567ec92a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is how I could get one page\n",
    "website = 'https://www.scrapethissite.com/pages/forms/'\n",
    "tables = pd.read_html(website)\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f91e46f-0e49-4d3b-a948-ac916e1aae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd1991-31fc-45b4-bca4-db82e098f173",
   "metadata": {},
   "source": [
    "## Pickle - binary data formats\n",
    "\n",
    "DataFrame objects have a .to_pickle() method that is great for storing python data. Pickled files have the advantage of preserving python data types but the disadvantage that they are not easily readable by other programming languages. Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4e5e978-efce-4c67-a11b-6a3b79c6f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in example 1 again\n",
    "df = pd.read_csv(\"data/ex1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db99407e-94f8-44e8-aa7e-c4c8be9a6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets write the file as a pickle\n",
    "df.to_pickle(\"frame_pickle.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4946809d-1bdf-4c04-9607-7b40f4d4aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\u0005�f\u0003\u0000\u0000\u0000\u0000\u0000\u0000�\u0011pandas.core.frame��\tDataFrame���)��}�(�\u0004_mgr��\u001e",
      "pandas.core.internals.managers��\f",
      "BlockManager����\u0016pandas._libs.internals��\u000f_unpickle_block����\u0013numpy._core.numeric��\u000b",
      "_frombuffer���(�`\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0007\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000b",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\f",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000��\u0005numpy��\u0005dtype����\u0002i8�����R�(K\u0003�\u0001<�NNNJ����J����K\u0000t�bK\u0004K\u0003���\u0001C�t�R�builtins��\u0005slice���K\u0000K\u0004K\u0001��R�K\u0002��R�h\u000b",
      "�\u0016numpy._core.multiarray��\f",
      "_reconstruct���h\u0010�\u0007ndarray���K\u0000��C\u0001b���R�(K\u0001K\u0001K\u0003��h\u0012�\u0002O8�����R�(K\u0003�\u0001|�NNNJ����J����K?t�b�]�(�\u0005hello��\u0005world��\u0003foo�et�bh\u001e",
      "K\u0004K\u0005K\u0001��R�K\u0002��R���]�(�\u0018pandas.core.indexes.base��\n",
      "_new_Index���h=�\u0005Index���}�(�\u0004data�h%h'K\u0000��h)��R�(K\u0001K\u0005��h/�]�(�\u0001a��\u0001b��\u0001c��\u0001d��\u0007message�et�b�\u0004name�Nu��R�h?�\u0019pandas.core.indexes.range��\n",
      "RangeIndex���}�(hON�\u0005start�K\u0000�\u0004stop�K\u0003�\u0004step�K\u0001u��R�e��R��\u0004_typ��\tdataframe��\t_metadata�]��\u0005attrs�}��\u0006_flags�}��\u0017allows_duplicate_labels��sub."
     ]
    }
   ],
   "source": [
    "# Lets look to see what is in the file\n",
    "!cat frame_pickle.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc22af-6d83-4b7a-b04f-e914444b2e4b",
   "metadata": {},
   "source": [
    "Notice that the file is not human readable! This is a binary data format. \n",
    "\n",
    "You should only use Pickle for short term data storage. Changes to python could mean that the data is not readable over the long term. Programmers try to preserve backward compatibility, but there is no absolute guarantee. Pickle is GREAT for when you need to save data in the short term to be available for Python codes.\n",
    "\n",
    "## Reading Excel Files\n",
    "\n",
    "Pandas does have a package to read .xlsx files created by Microsoft Excel. To use this package we need to make sure a few modules are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4236b570-2639-4334-a434-1cf7d9c5c375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y openpyxl xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606091b-00cf-4020-b64b-ec2ce1dfbace",
   "metadata": {},
   "source": [
    "One issue with .xslx files is that they can contain some pretty complex data arranged in sheets. If you just call .read_xlsx() pandas will try to just read one sheet and you could be missing a bunch of your data. Instead you can explore the file using .ExcelFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "975f7728-3b82-4738-947b-f95e252da693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data into the xlsx parser\n",
    "xlsx = pd.ExcelFile(\"data/ex1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e8f32ee-bd85-4f1d-91f2-4908f49f31c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.excel._base.ExcelFile at 0x70e023e13b10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice this does not let you see the data\n",
    "xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "878e7c5c-8c58-4f56-9604-1792f444ec81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sheet1', 'Sheet2']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sheet names\n",
    "xlsx.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20a3267b-345b-4609-a5bf-afcba53266cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  a   b   c   d message\n",
       "0           0  1   2   3   4   hello\n",
       "1           1  5   6   7   8   world\n",
       "2           2  9  10  11  12     foo"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the sheet you want\n",
    "# This is a data frame - you could totally just use xlsx.parse if you want\n",
    "# df = xlsx.parse(sheet_name=\"Sheet1\") would work\n",
    "xlsx.parse(sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df653c44-ce07-4e2d-aa3a-9fb30364b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could read the index for the first column\n",
    "xlsx.parse(sheet_name=\"Sheet1\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5eebc2-87ad-41a6-91d8-a1586ff4677e",
   "metadata": {},
   "source": [
    "Pandas has a built in read_excel() function. It is easy to remember! But beware of missing sheets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ca5a4ad-303c-4525-b135-3ddf4154313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  a   b   c   d message\n",
       "0           0  1   2   3   4   hello\n",
       "1           1  5   6   7   8   world\n",
       "2           2  9  10  11  12     foo"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that if we just call read_excel we only get the first sheet!\n",
    "# There is no error to tell us we are missing a sheet.\n",
    "df = pd.read_excel(\"data/ex1.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d41d8ab-c8bd-4392-a5f2-eb04f2ea3b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   a   b   c   d message\n",
       " 0  1   2   3   4   hello\n",
       " 1  5   6   7   8   world\n",
       " 2  9  10  11  12     foo,\n",
       "     a     b   c    d message\n",
       " 0  12    15  54   34   hello\n",
       " 1  23  5656  34  364   world\n",
       " 2  45     2   1   12     foo]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I might have to loop over the sheets to read them all in\n",
    "df_list = []\n",
    "for sn in xlsx.sheet_names:\n",
    "    df = pd.read_excel(\"data/ex1.xlsx\", sheet_name=sn,index_col=0)\n",
    "    df_list.append(df)\n",
    "df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c742b5-3987-4a14-be8a-2d2399868f4d",
   "metadata": {},
   "source": [
    "## Interacting with Web APIs.\n",
    "\n",
    "Anytime you are thinking about scraping data from a website you should first look to see if they have an API available for getting the data. Always download the data directly or use an API before choosing to scrape a website. Many websites are being written now to stop people from basic webs scraping because scraping can cause lots of problems. Websites don't hate scraping, but they want to make sure access is controlled, fair, legal, and doesn't break the site. That's why many provide official APIs as a safer alternative.\n",
    "\n",
    "First let's install a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a68182c4-98c0-4231-8ac2-86be70f81251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80a65d15-e258-4e9f-a3ec-3623bb2f82fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# Example: Free TheSportsDB API (soccer team lookup)\n",
    "# Based on the information here: https://www.thesportsdb.com/documentation#search_v1\n",
    "# We can use the URL\n",
    "url = \"https://www.thesportsdb.com/api/v1/json/3/searchteams.php\"\n",
    "# Then to find a specific team we add\n",
    "# https://www.thesportsdb.com/api/v1/json/123/searchteams.php?t=Arsenal\n",
    "# We can use this my sending a parameter into requests\n",
    "params = {\"t\": \"San Diego Wave\"}  # Search for team name\n",
    "\n",
    "# Get the data\n",
    "resp = requests.get(url, params=params)\n",
    "# Check that we got actual data\n",
    "resp.raise_for_status()\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97f2a5d9-c41a-4c59-9839-d8d3f89665a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'teams': [{'idTeam': '145094',\n",
       "   'idESPN': '0',\n",
       "   'idAPIfootball': '18451',\n",
       "   'intLoved': '1',\n",
       "   'strTeam': 'San Diego Wave',\n",
       "   'strTeamAlternate': '',\n",
       "   'strTeamShort': '',\n",
       "   'intFormedYear': '2021',\n",
       "   'strSport': 'Soccer',\n",
       "   'strLeague': 'American NWSL',\n",
       "   'idLeague': '4521',\n",
       "   'strLeague2': 'American NWSL Challenge Cup',\n",
       "   'idLeague2': '5178',\n",
       "   'strLeague3': 'CONCACAF W Champions Cup',\n",
       "   'idLeague3': '5640',\n",
       "   'strLeague4': '',\n",
       "   'idLeague4': None,\n",
       "   'strLeague5': '',\n",
       "   'idLeague5': None,\n",
       "   'strLeague6': '',\n",
       "   'idLeague6': None,\n",
       "   'strLeague7': '',\n",
       "   'idLeague7': None,\n",
       "   'strDivision': None,\n",
       "   'idVenue': '24552',\n",
       "   'strStadium': 'Snapdragon Stadium',\n",
       "   'strKeywords': '',\n",
       "   'strRSS': '',\n",
       "   'strLocation': 'San Diego, California',\n",
       "   'intStadiumCapacity': '35000',\n",
       "   'strWebsite': '',\n",
       "   'strFacebook': '',\n",
       "   'strTwitter': '',\n",
       "   'strInstagram': '',\n",
       "   'strDescriptionEN': \"San Diego Wave FC is a National Women's Soccer League expansion team that is expected to begin play in 2022. The team will be based in San Diego, California. The team is owned by Ron Burkle.\\r\\n\\r\\nThe team will be the San Diego area's first women's professional soccer team since 2003, when the Women's United Soccer Association folded and forced the San Diego Spirit to disband.\",\n",
       "   'strDescriptionDE': None,\n",
       "   'strDescriptionFR': None,\n",
       "   'strDescriptionCN': None,\n",
       "   'strDescriptionIT': None,\n",
       "   'strDescriptionJP': None,\n",
       "   'strDescriptionRU': None,\n",
       "   'strDescriptionES': None,\n",
       "   'strDescriptionPT': None,\n",
       "   'strDescriptionSE': None,\n",
       "   'strDescriptionNL': None,\n",
       "   'strDescriptionHU': None,\n",
       "   'strDescriptionNO': None,\n",
       "   'strDescriptionIL': None,\n",
       "   'strDescriptionPL': None,\n",
       "   'strColour1': '',\n",
       "   'strColour2': '',\n",
       "   'strColour3': '',\n",
       "   'strGender': 'Female',\n",
       "   'strCountry': 'United States',\n",
       "   'strBadge': 'https://r2.thesportsdb.com/images/media/team/badge/hb5yo61644517945.png',\n",
       "   'strLogo': 'https://r2.thesportsdb.com/images/media/team/logo/tpws861652790115.png',\n",
       "   'strFanart1': 'https://r2.thesportsdb.com/images/media/team/fanart/m145vl1652791877.jpg',\n",
       "   'strFanart2': 'https://r2.thesportsdb.com/images/media/team/fanart/lbt1x51652791632.jpg',\n",
       "   'strFanart3': 'https://r2.thesportsdb.com/images/media/team/fanart/tdl5qq1652791678.jpg',\n",
       "   'strFanart4': 'https://r2.thesportsdb.com/images/media/team/fanart/mo0pga1652791758.jpg',\n",
       "   'strBanner': 'https://r2.thesportsdb.com/images/media/team/banner/o5f9ca1652792180.jpg',\n",
       "   'strEquipment': 'https://r2.thesportsdb.com/images/media/team/equipment/z8gk2w1715200127.png',\n",
       "   'strYoutube': '',\n",
       "   'strLocked': 'unlocked'}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19457b09-5945-450d-a561-1fa2048e9514",
   "metadata": {},
   "source": [
    "The data is in a dictionary format and to play around with it in Pandas you would need to do some work. You could imagine importing a few different teams each as a pandas series and then creating a data frame with all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3cf06128-e47a-408a-8380-9007245f8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.thesportsdb.com/api/v1/json/3/searchteams.php\"\n",
    "\n",
    "my_teams = [\"San Diego Wave\", \"Portland Trail Blazers\",\"Liverpool\", \"San Francisco Unicorns\"]\n",
    "series_list = []\n",
    "for team in my_teams:\n",
    "    params = {\"t\": team}  # Search for team name\n",
    "    resp = requests.get(url, params=params)\n",
    "    # Check that we got actual data\n",
    "    if resp.status_code == 200:\n",
    "        data = resp.json()\n",
    "        series_list.append(pd.Series(data['teams'][0]))\n",
    "    else:\n",
    "        print(f\"Unable to find {team}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87301397-c6f9-4611-91fb-c67936d70403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTeam</th>\n",
       "      <th>idESPN</th>\n",
       "      <th>idAPIfootball</th>\n",
       "      <th>intLoved</th>\n",
       "      <th>strTeam</th>\n",
       "      <th>strTeamAlternate</th>\n",
       "      <th>strTeamShort</th>\n",
       "      <th>intFormedYear</th>\n",
       "      <th>strSport</th>\n",
       "      <th>strLeague</th>\n",
       "      <th>...</th>\n",
       "      <th>strBadge</th>\n",
       "      <th>strLogo</th>\n",
       "      <th>strFanart1</th>\n",
       "      <th>strFanart2</th>\n",
       "      <th>strFanart3</th>\n",
       "      <th>strFanart4</th>\n",
       "      <th>strBanner</th>\n",
       "      <th>strEquipment</th>\n",
       "      <th>strYoutube</th>\n",
       "      <th>strLocked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145094</td>\n",
       "      <td>0</td>\n",
       "      <td>18451</td>\n",
       "      <td>1</td>\n",
       "      <td>San Diego Wave</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021</td>\n",
       "      <td>Soccer</td>\n",
       "      <td>American NWSL</td>\n",
       "      <td>...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/l...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/e...</td>\n",
       "      <td></td>\n",
       "      <td>unlocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134888</td>\n",
       "      <td>None</td>\n",
       "      <td>156</td>\n",
       "      <td>None</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td></td>\n",
       "      <td>POR</td>\n",
       "      <td>1970</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NBA</td>\n",
       "      <td>...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/l...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/e...</td>\n",
       "      <td></td>\n",
       "      <td>unlocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133602</td>\n",
       "      <td>364</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>LFC, Liverpool FC</td>\n",
       "      <td>LIV</td>\n",
       "      <td>1892</td>\n",
       "      <td>Soccer</td>\n",
       "      <td>English Premier League</td>\n",
       "      <td>...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/l...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/f...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://www.thesportsdb.com/images/media/team/...</td>\n",
       "      <td>youtube.com/user/LiverpoolFC</td>\n",
       "      <td>unlocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>San Francisco Unicorns</td>\n",
       "      <td>SF Unicorns</td>\n",
       "      <td>SFU</td>\n",
       "      <td>2023</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>Major League Cricket</td>\n",
       "      <td>...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/b...</td>\n",
       "      <td>https://r2.thesportsdb.com/images/media/team/l...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>www.youtube.com/@SFOUnicorns</td>\n",
       "      <td>unlocked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTeam idESPN idAPIfootball intLoved                 strTeam  \\\n",
       "0  145094      0         18451        1          San Diego Wave   \n",
       "1  134888   None           156     None  Portland Trail Blazers   \n",
       "2  133602    364            40       11               Liverpool   \n",
       "3  147493      0             0        1  San Francisco Unicorns   \n",
       "\n",
       "    strTeamAlternate strTeamShort intFormedYear    strSport  \\\n",
       "0                                          2021      Soccer   \n",
       "1                             POR          1970  Basketball   \n",
       "2  LFC, Liverpool FC          LIV          1892      Soccer   \n",
       "3        SF Unicorns          SFU          2023     Cricket   \n",
       "\n",
       "                strLeague  ...  \\\n",
       "0           American NWSL  ...   \n",
       "1                     NBA  ...   \n",
       "2  English Premier League  ...   \n",
       "3    Major League Cricket  ...   \n",
       "\n",
       "                                            strBadge  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "3  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "\n",
       "                                             strLogo  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/l...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/l...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/l...   \n",
       "3  https://r2.thesportsdb.com/images/media/team/l...   \n",
       "\n",
       "                                          strFanart1  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "3                                               None   \n",
       "\n",
       "                                          strFanart2  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "3                                               None   \n",
       "\n",
       "                                          strFanart3  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "3                                               None   \n",
       "\n",
       "                                          strFanart4  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/f...   \n",
       "3                                               None   \n",
       "\n",
       "                                           strBanner  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "2  https://r2.thesportsdb.com/images/media/team/b...   \n",
       "3                                               None   \n",
       "\n",
       "                                        strEquipment  \\\n",
       "0  https://r2.thesportsdb.com/images/media/team/e...   \n",
       "1  https://r2.thesportsdb.com/images/media/team/e...   \n",
       "2  https://www.thesportsdb.com/images/media/team/...   \n",
       "3                                               None   \n",
       "\n",
       "                     strYoutube strLocked  \n",
       "0                                unlocked  \n",
       "1                                unlocked  \n",
       "2  youtube.com/user/LiverpoolFC  unlocked  \n",
       "3  www.youtube.com/@SFOUnicorns  unlocked  \n",
       "\n",
       "[4 rows x 64 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(series_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db0191-3250-4bef-bf6e-8db72aadd48c",
   "metadata": {},
   "source": [
    "## Interacting with Databases\n",
    "\n",
    "In many instances data is not stored as a .txt, .json, etc file. Instead it is stored in a database. There are many kinds of databases and the choice of a database is highly dependent on the type, size, scalability, and performance needed for the system.\n",
    "\n",
    "Pandas does have the ability to interact with SQL-based relational databases. First lets create a database that we can play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c19b94a-2ae6-45bb-9b4b-5b9c2fca9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# We start by creating a table named \"test\" that tells SQLite what kind of data to expect\n",
    "# a - text up to 20 characters\n",
    "# b - text up to 20 characters\n",
    "# c - a floating-point number (REAL)\n",
    "# d - an integer\n",
    "# Notice this is just a string that contains the information in a tuple like format.\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "# We open or create a SQLite database\n",
    "# con is a connection object\n",
    "con = sqlite3.connect(\"mydata.sqlite\")\n",
    "# We create the table using our text query above\n",
    "con.execute(query)\n",
    "# We save the changes to the data base\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c3caa-1846-4a07-bc33-7184dd8171a5",
   "metadata": {},
   "source": [
    "Because **con** is a database connection object you can see what kind of commands you can run by typing\n",
    "\n",
    "    con.\n",
    "    \n",
    "and then pressing the TAB button. Remember you can always access the documentation with the ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64b9037e-7aab-4196-8270-698948cd6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare some data for the database - a list of tuples that matches query above\n",
    "data = [(\"Atlanta\", \"Georgia\", 1.25, 6),\n",
    "        (\"Tallahassee\", \"Florida\", 2.6, 3),\n",
    "        (\"Sacramento\", \"California\", 1.7, 5)]\n",
    "# Define placeholders\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "\n",
    "# Insert multiple rows into the data base\n",
    "con.executemany(stmt, data)\n",
    "# and save them\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8258e-2614-4570-b252-47517737c272",
   "metadata": {},
   "source": [
    "Now we are ready to interact with the database. We start by defining a cursor that will access the database. We need to use SQL statements (Structured Query Language), written as a Python string:\n",
    "\n",
    "- SELECT - tells the database you want to retrieve data.\n",
    "- $*$ - means all columns. Instead of listing column names one by one (a, b, c, d), you grab everything.\n",
    "- FROM test - says which table to select data from (here, the table is named test).\n",
    "\n",
    "Here is a website were you can learn more: https://www.w3schools.com/sql/sql_intro.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8704b205-215d-4806-854b-d8f581bbf083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x70e0b8894a40>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test\")\n",
    "cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb58977-e4ed-491f-a445-27aee9f253d5",
   "metadata": {},
   "source": [
    "Now we have options:\n",
    "\n",
    "- Use .fetchone() if you want to process rows one by one (e.g., in a loop).\n",
    "- Use .fetchmany(n) if you want to grab results in chunks.\n",
    "- Use .fetchall() if the dataset is small and you just want everything at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a133bb21-83f2-47c9-9634-adcf315a6c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Atlanta', 'Georgia', 1.25, 6),\n",
       " ('Tallahassee', 'Florida', 2.6, 3),\n",
       " ('Sacramento', 'California', 1.7, 5)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a227e44a-1709-4784-b790-ac9397d4f0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Atlanta', 'Georgia', 1.25, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test\")\n",
    "rows = cursor.fetchone()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6021a971-f427-4948-a1ef-032b86d3806f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Atlanta', 'Georgia', 1.25, 6), ('Tallahassee', 'Florida', 2.6, 3)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test\")\n",
    "rows = cursor.fetchmany(2)\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de1c5b-6e35-40e2-99ca-8b22d4a06579",
   "metadata": {},
   "source": [
    "SQL has options for more refined searches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f783e50-891b-4f2e-bfd9-ca7704de8be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sacramento', 'California', 1.7, 5)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test WHERE b=='California'\")\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e2aa5a4-a11a-4156-99e0-a935668de776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Atlanta', 'Georgia', 1.25, 6), ('Sacramento', 'California', 1.7, 5)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test WHERE d>3\")\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fc4d4314-e39a-45fb-a160-9425471b1c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tallahassee', 'Florida', 2.6, 3),\n",
       " ('Sacramento', 'California', 1.7, 5),\n",
       " ('Atlanta', 'Georgia', 1.25, 6)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test ORDER BY c DESC\")\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3785e0-2752-4e63-81a7-160ae34bb4f4",
   "metadata": {},
   "source": [
    "## Code provided by Websites\n",
    "\n",
    "Some websites provide modules and Python code that help you read your data directly into Python. For example Kaggle provides information about how to download the data and get the path to the data directly in Python. \n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b63c083-dd81-4bb9-837a-1affc748ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.13).\n",
      "Path to dataset files: /home/bellajagu/.cache/kagglehub/datasets/mdsultanulislamovi/student-stress-monitoring-datasets/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version of the data\n",
    "path = kagglehub.dataset_download(\"mdsultanulislamovi/student-stress-monitoring-datasets\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "de3e5ae1-7cf9-406c-978a-7d8b622c6aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stress_Dataset.csv', 'StressLevelDataset.csv']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the data directory path\n",
    "path = '/home/bellajagu/.cache/kagglehub/datasets/mdsultanulislamovi/student-stress-monitoring-datasets/versions/1/'\n",
    "# List all the files in the directory\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d987e0b0-6f48-49dc-b39c-423265783de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Have you recently experienced stress in your life?</th>\n",
       "      <th>Have you noticed a rapid heartbeat or palpitations?</th>\n",
       "      <th>Have you been dealing with anxiety or tension recently?</th>\n",
       "      <th>Do you face any sleep problems or difficulties falling asleep?</th>\n",
       "      <th>Have you been dealing with anxiety or tension recently?.1</th>\n",
       "      <th>Have you been getting headaches more often than usual?</th>\n",
       "      <th>Do you get irritated easily?</th>\n",
       "      <th>Do you have trouble concentrating on your academic tasks?</th>\n",
       "      <th>...</th>\n",
       "      <th>Are you facing any difficulties with your professors or instructors?</th>\n",
       "      <th>Is your working environment unpleasant or stressful?</th>\n",
       "      <th>Do you struggle to find time for relaxation and leisure activities?</th>\n",
       "      <th>Is your hostel or home environment causing you difficulties?</th>\n",
       "      <th>Do you lack confidence in your academic performance?</th>\n",
       "      <th>Do you lack confidence in your choice of academic subjects?</th>\n",
       "      <th>Academic and extracurricular activities conflicting for you?</th>\n",
       "      <th>Do you attend classes regularly?</th>\n",
       "      <th>Have you gained/lost weight?</th>\n",
       "      <th>Which type of stress do you primarily experience?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Eustress (Positive Stress) - Stress that motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Eustress (Positive Stress) - Stress that motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Eustress (Positive Stress) - Stress that motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Eustress (Positive Stress) - Stress that motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Eustress (Positive Stress) - Stress that motiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Have you recently experienced stress in your life?  \\\n",
       "0       0   20                                                  3    \n",
       "1       0   20                                                  2    \n",
       "2       0   20                                                  5    \n",
       "3       1   20                                                  3    \n",
       "4       0   20                                                  3    \n",
       "\n",
       "   Have you noticed a rapid heartbeat or palpitations?  \\\n",
       "0                                                  4     \n",
       "1                                                  3     \n",
       "2                                                  4     \n",
       "3                                                  4     \n",
       "4                                                  3     \n",
       "\n",
       "   Have you been dealing with anxiety or tension recently?  \\\n",
       "0                                                  2         \n",
       "1                                                  2         \n",
       "2                                                  2         \n",
       "3                                                  3         \n",
       "4                                                  3         \n",
       "\n",
       "   Do you face any sleep problems or difficulties falling asleep?  \\\n",
       "0                                                  5                \n",
       "1                                                  1                \n",
       "2                                                  2                \n",
       "3                                                  2                \n",
       "4                                                  2                \n",
       "\n",
       "   Have you been dealing with anxiety or tension recently?.1  \\\n",
       "0                                                  1           \n",
       "1                                                  1           \n",
       "2                                                  1           \n",
       "3                                                  2           \n",
       "4                                                  2           \n",
       "\n",
       "   Have you been getting headaches more often than usual?  \\\n",
       "0                                                  2        \n",
       "1                                                  1        \n",
       "2                                                  3        \n",
       "3                                                  3        \n",
       "4                                                  4        \n",
       "\n",
       "   Do you get irritated easily?  \\\n",
       "0                             1   \n",
       "1                             1   \n",
       "2                             4   \n",
       "3                             4   \n",
       "4                             4   \n",
       "\n",
       "   Do you have trouble concentrating on your academic tasks?  ...  \\\n",
       "0                                                  2          ...   \n",
       "1                                                  4          ...   \n",
       "2                                                  2          ...   \n",
       "3                                                  3          ...   \n",
       "4                                                  4          ...   \n",
       "\n",
       "   Are you facing any difficulties with your professors or instructors?  \\\n",
       "0                                                  3                      \n",
       "1                                                  3                      \n",
       "2                                                  2                      \n",
       "3                                                  1                      \n",
       "4                                                  2                      \n",
       "\n",
       "   Is your working environment unpleasant or stressful?  \\\n",
       "0                                                  1      \n",
       "1                                                  2      \n",
       "2                                                  2      \n",
       "3                                                  1      \n",
       "4                                                  3      \n",
       "\n",
       "   Do you struggle to find time for relaxation and leisure activities?  \\\n",
       "0                                                  4                     \n",
       "1                                                  1                     \n",
       "2                                                  2                     \n",
       "3                                                  2                     \n",
       "4                                                  1                     \n",
       "\n",
       "   Is your hostel or home environment causing you difficulties?  \\\n",
       "0                                                  1              \n",
       "1                                                  1              \n",
       "2                                                  1              \n",
       "3                                                  1              \n",
       "4                                                  2              \n",
       "\n",
       "   Do you lack confidence in your academic performance?  \\\n",
       "0                                                  2      \n",
       "1                                                  3      \n",
       "2                                                  4      \n",
       "3                                                  2      \n",
       "4                                                  2      \n",
       "\n",
       "   Do you lack confidence in your choice of academic subjects?  \\\n",
       "0                                                  1             \n",
       "1                                                  2             \n",
       "2                                                  1             \n",
       "3                                                  1             \n",
       "4                                                  4             \n",
       "\n",
       "   Academic and extracurricular activities conflicting for you?  \\\n",
       "0                                                  3              \n",
       "1                                                  1              \n",
       "2                                                  1              \n",
       "3                                                  1              \n",
       "4                                                  2              \n",
       "\n",
       "   Do you attend classes regularly?  Have you gained/lost weight?  \\\n",
       "0                                 1                             2   \n",
       "1                                 4                             2   \n",
       "2                                 2                             1   \n",
       "3                                 5                             3   \n",
       "4                                 2                             2   \n",
       "\n",
       "   Which type of stress do you primarily experience?  \n",
       "0  Eustress (Positive Stress) - Stress that motiv...  \n",
       "1  Eustress (Positive Stress) - Stress that motiv...  \n",
       "2  Eustress (Positive Stress) - Stress that motiv...  \n",
       "3  Eustress (Positive Stress) - Stress that motiv...  \n",
       "4  Eustress (Positive Stress) - Stress that motiv...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now load the file you want to look at into Pandas\n",
    "file = path+'Stress_Dataset.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a856998d-685f-41da-a549-a6029ab0715a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In Data Science you need to be willing and able to interact with LOTS of different data types, file types, and query types. For most of this class we will read the data in directly. DATA 211 Database Management will give you lots more tools for creating and interacting with SQL type databases.\n",
    "\n",
    "\n",
    "## Homework 3\n",
    "\n",
    "Go to Kaggle Datasets: https://www.kaggle.com/datasets\n",
    "\n",
    "Find a data set that you are interested in looking at. You are welcome to work together and choose a data set as a group! You should read in this data and do some basic statistics on the data set. Answer the following questions:\n",
    "\n",
    "1. How many variables and observations?\n",
    "2. What type of data is contained?\n",
    "3. Are there any NaNs or weird data types that you can see?\n",
    "4. Most Kaggle datasets contain some basic stats or visualizations. See if you can recreate some of the plots or data you see on the website.\n",
    "5. Come up with at least one question of your own that you can answer by analyzing the data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc43f2c-0f38-490a-8495-9e070e9b9234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
